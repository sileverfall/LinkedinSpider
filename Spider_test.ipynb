{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "import time\n",
    "from urllib.parse import unquote\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "import re\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(laccount, lpassword):\n",
    "    \"\"\" 根据账号密码登录linkedin \"\"\"\n",
    "    s = requests.Session()\n",
    "    r = s.get('https://www.linkedin.com/uas/login')\n",
    "    tree = etree.HTML(r.content)\n",
    "    loginCsrfParam = ''.join(tree.xpath('//input[@id=\"loginCsrfParam-login\"]/@value'))\n",
    "    csrfToken = ''.join(tree.xpath('//input[@id=\"csrfToken-login\"]/@value'))\n",
    "    sourceAlias = ''.join(tree.xpath('//input[@id=\"sourceAlias-login\"]/@value'))\n",
    "    isJsEnabled = ''.join(tree.xpath('//input[@name=\"isJsEnabled\"]/@value'))\n",
    "    source_app = ''.join(tree.xpath('//input[@name=\"source_app\"]/@value'))\n",
    "    tryCount = ''.join(tree.xpath('//input[@id=\"tryCount\"]/@value'))\n",
    "    clickedSuggestion = ''.join(tree.xpath('//input[@id=\"clickedSuggestion\"]/@value'))\n",
    "    signin = ''.join(tree.xpath('//input[@name=\"signin\"]/@value'))\n",
    "    session_redirect = ''.join(tree.xpath('//input[@name=\"session_redirect\"]/@value'))\n",
    "    trk = ''.join(tree.xpath('//input[@name=\"trk\"]/@value'))\n",
    "    fromEmail = ''.join(tree.xpath('//input[@name=\"fromEmail\"]/@value'))\n",
    "\n",
    "    payload = {\n",
    "        'isJsEnabled': isJsEnabled,\n",
    "        'source_app': source_app,\n",
    "        'tryCount': tryCount,\n",
    "        'clickedSuggestion': clickedSuggestion,\n",
    "        'session_key': laccount,\n",
    "        'session_password': lpassword,\n",
    "        'signin': signin,\n",
    "        'session_redirect': session_redirect,\n",
    "        'trk': trk,\n",
    "        'loginCsrfParam': loginCsrfParam,\n",
    "        'fromEmail': fromEmail,\n",
    "        'csrfToken': csrfToken,\n",
    "        'sourceAlias': sourceAlias\n",
    "    }\n",
    "    s.post('https://www.linkedin.com/uas/login-submit', data=payload)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = login(laccount='tsb1071463@gmail.com', lpassword='Alisa0504')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the company you want to crawl:台新\n"
     ]
    }
   ],
   "source": [
    "company_name = input('Input the company you want to crawl:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpage = 50 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_Linkedin_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.google.com/search?q=Linkedin+' + quote(company_name)+'&oq=Linkedin+'+ quote(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url,timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "soup = bs(res.text,\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Taishin International Commercial Bank | LinkedIn',\n",
       "  'https://www.linkedin.com/company/%25E5%258F%25B0%25E6%2596%25B0%25E5%259C%258B%25E9%259A%259B%25E5%2595%2586%25E6%25A5%25AD%25E9%258A%2580%25E8%25A1%258C%25E8%2582%25A1%25E4%25BB%25BD%25E6%259C%2589%25E9%2599%2590%25E5%2585%25AC%25E5%258F%25B8'),\n",
       " ('Taishin Financial Holdings | LinkedIn',\n",
       "  'https://www.linkedin.com/company/taishin-international-bank'),\n",
       " ('Julia Kan - Project Manager - 台新金控| LinkedIn',\n",
       "  'https://tw.linkedin.com/in/julia-kan-13671612b'),\n",
       " ('Anny Lee - 經理- 台新銀行| LinkedIn',\n",
       "  'https://tw.linkedin.com/in/anny-lee-a630aa163'),\n",
       " ('趙毓齡- 經理- 台新國際商業銀行股份有限公司| LinkedIn',\n",
       "  'https://tw.linkedin.com/in/%25E6%25AF%2593%25E9%25BD%25A1-%25E8%25B6%2599-725ba3118'),\n",
       " ('Dickson Fong - AVP compliance - 台新國際商業銀行| LinkedIn',\n",
       "  'https://hk.linkedin.com/in/dickson-fong-710064170'),\n",
       " ('LC AB 台新銀行郭立程- VP - Taishin International Bank | LinkedIn',\n",
       "  'https://hk.linkedin.com/in/lc-ab-%25E5%258F%25B0%25E6%2596%25B0%25E9%258A%2580%25E8%25A1%258C-%25E9%2583%25AD%25E7%25AB%258B%25E7%25A8%258B-959170b5'),\n",
       " ('孔祥俊- 協理- 台新國際商業銀行股份有限公司| LinkedIn',\n",
       "  'https://tw.linkedin.com/in/%25E7%25A5%25A5%25E4%25BF%258A-%25E5%25AD%2594-130047104'),\n",
       " ('Kristine Tsai - 儲備幹部- 台新銀行| LinkedIn',\n",
       "  'https://tw.linkedin.com/in/kristine-tsai-776875134'),\n",
       " ('Yu-Ting Chen - Mutual Fund Product Manager - 台新國際 ... - LinkedIn',\n",
       "  'https://tw.linkedin.com/in/yu-ting-chen-5382679b')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i.text,i.parent['href'].split('q=')[1].split('&')[0]) for i in soup.select('a > div.BNeawe.vvjwJb.AP7Wnd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "failure = 0\n",
    "while len(url) > 0 and failure < 10:\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "    except Exception as e:\n",
    "        failure += 1\n",
    "        continue\n",
    "    if r.status_code == 200:\n",
    "        hrefs=[i.parent['href'].split('q=')[1].split('&')[0] for i in soup.select('a > div.BNeawe.vvjwJb.AP7Wnd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "failure = 0\n",
    "while len(url) > 0 and failure < 10:\n",
    "    try:\n",
    "        r = requests.get(url, timeout=10)\n",
    "    except Exception as e:\n",
    "        failure += 1\n",
    "        continue\n",
    "    if r.status_code == 200:\n",
    "#         hrefs = list(set(re.findall('\"(http://www\\.baidu\\.com/link\\?url=.*?)\"', r.text))) \n",
    "        hrefs = [i['href'] for i in soup.select('a')]    # 一页有10个搜索结果\n",
    "        for href in hrefs:\n",
    "            crawl(href, copy.deepcopy(s))\n",
    "        results += hrefs\n",
    "        tree = etree.HTML(r.content)\n",
    "        nextpage_txt = tree.xpath('//div[@id=\"page\"]/a[@class=\"n\" and contains(text(), \"下一页\")]/@href'.decode('utf8'))\n",
    "        url = 'http://www.baidu.com' + nextpage_txt[0].strip() if nextpage_txt else ''\n",
    "        failure = 0\n",
    "        maxpage -= 1\n",
    "        if maxpage <= 0:\n",
    "            break\n",
    "    else:\n",
    "        failure += 2\n",
    "        print ('search failed: %s' % r.status_code)\n",
    "if failure >= 10:\n",
    "    print ('search failed: %s' % url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linkedin_url(url, s):\n",
    "    try:\n",
    "        r = s.get(url, allow_redirects=False)\n",
    "        if r.status_code == 999 and 'Location' in r.headers.keys() and 'linkedin.com/in/' in r.headers['Location']:\n",
    "            return r.headers['Location']\n",
    "    except Exception as e:\n",
    "        print ('get linkedin url failed: %s' % url)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs=[i.parent['href'].split('q=')[1].split('&')[0] for i in soup.select('a > div.BNeawe.vvjwJb.AP7Wnd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://tw.linkedin.com/in/julia-kan-13671612b'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hrefs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://tw.linkedin.com/in/']"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'^https://tw\\.linkedin\\.com/in/',hrefs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = copy.deepcopy(s).get(hrefs[0],allow_redirects=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView({'Date': 'Wed, 07 Aug 2019 09:27:24 GMT', 'X-Li-Pop': 'prod-ehk1', 'X-LI-Proto': 'http/1.1', 'X-LI-UUID': 'GmxU69yZuBVgWt5ffisAAA==', 'Set-Cookie': 'trkCode=ripf; Max-Age=5, trkInfo=AQHCIQJy9t_lagAAAWxrZ4xgHClzlcLg4OgzrKTS9wyIzildH-SyCjbU3hnB2uJTXfc9oAPVV-HWdpWWf4laoUartcW4LviILqxw3TwFuXJVGBRcMlLHtlNe1m5TLANSZV1S4lU=; Max-Age=5, rtc=AQFgSEmiBcZv_wAAAWxrZ4xgsss-o4oDraVJ5ZI7KwkT1DEidZWVUDSOV-rap6gM_E25_Z6s3AnFw_7wJRq9vX5SFj8I1yAPnB06WamHBsM8XRvfB6vAczcYB63qwl8jW7AC7Dz9-Vt18Nfi9mioXT6Q6nsswreERNBQ8J-BtV8Eh4e3V33JNuRHT4rDumeKgfJoEJ65h8z4R7ILSUFj-SEFtHoSM8CMavVc7tj9ZxFBXNenwS4RBy5-ExWK67qpFg110F7NwR_s6tj-4gloPopivgAg9BCznjCykw==; Max-Age=120; path=/; domain=.linkedin.com', 'Content-Length': '1461', 'Content-Type': 'text/html'})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.headers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get linkedin url failed: \n",
      "get linkedin url failed: \n",
      "get linkedin url failed: \n",
      "get linkedin url failed: \n",
      "get linkedin url failed: \n",
      "get linkedin url failed: \n",
      "get linkedin url failed: \n",
      "get linkedin url failed: \n",
      "get linkedin url failed: \n",
      "get linkedin url failed: \n"
     ]
    }
   ],
   "source": [
    "for href in hrefs:\n",
    "    try:\n",
    "        url = get_linkedin_url(url, copy.deepcopy(s))\n",
    "        if len(url) > 0 and url not in LINKS_FINISHED:\n",
    "            LINKS_FINISHED.append(url)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl(url, s):\n",
    "    \"\"\" 抓取每一个搜索结果 \"\"\"\n",
    "    try:\n",
    "        url = get_linkedin_url(url, copy.deepcopy(s)).replace('cn.linkedin.com', 'www.linkedin.com')  \n",
    "        if len(url) > 0 and url not in LINKS_FINISHED:\n",
    "            LINKS_FINISHED.append(url)\n",
    "\n",
    "            failure = 0\n",
    "            while failure < 10:\n",
    "                try:\n",
    "                    r = s.get(url, timeout=10)\n",
    "                except Exception as e:\n",
    "                    failure += 1\n",
    "                    continue\n",
    "                if r.status_code == 200:\n",
    "                    parse(r.content, url)\n",
    "                    break\n",
    "                else:\n",
    "                    print ('%s %s' % (r.status_code, url))\n",
    "                    failure += 2\n",
    "            if failure >= 10:\n",
    "                print ('Failed: %s' % url)\n",
    "    except Exception as e:\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
